{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac8ea04",
   "metadata": {},
   "source": [
    "# MNIST Lightning training - Amazon SageMaker Training Job\n",
    "\n",
    "\n",
    "Train a MNIST classification model created using Pytorch Lightning and logging the training, validation, and test metrics using Amazon SageMaker Experiments.\n",
    "\n",
    "\n",
    "---\n",
    "This notebook has been designed to work in Amazon SageMaker Studio with `Python 3 (PyTorch 1.12 Python 3.8 CPU Optimized)`.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook there are two examples:\n",
    "- training on a single GPU on a `ml.g4dn.xlarge` instance\n",
    "- training on a 4 GPU on a `ml.g4dn.12xlarge` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ddd78-eb38-47cb-8d80-230649b3d508",
   "metadata": {},
   "source": [
    "#### Install and update libraries\n",
    "This notebook requires a version of SageMaker Python SDK greater than 2.123.0 to be able to use the [recently released new capabilities of SageMaker Experiments](https://aws.amazon.com/about-aws/whats-new/2022/12/amazon-sagemaker-experiments-ml-experiment-management-diverse-ides/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991456a-4f06-43fb-8c13-0769013858d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install -U \"sagemaker >= 2.123.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284686f-61a4-4f0c-8f6a-126daa922030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.debugger import DebuggerHookConfig, Rule, TensorBoardOutputConfig, rule_configs\n",
    "from sagemaker.experiments import Run\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.utils import name_from_base\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d08d0",
   "metadata": {},
   "source": [
    "Definitions and objects necessary for running the Training Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "prefix = \"pytorch-demo-mnist\"\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe465f9d-ad18-40ba-b2cc-324304bf0aa7",
   "metadata": {},
   "source": [
    "## Upload datasets\n",
    "\n",
    "All training jobs in this sample use the same dataset. Instead of downloading it from the public repository for every training job, we'll upload a copy to S3 and then use [FastFile mode](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html) to serve the data to the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a98f0-556e-4aa2-b1bf-25b22bf46ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
    "\n",
    "MNIST(\"data\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069de4f-c78e-4302-90e7-11cfdeae34d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_s3_uri = sagemaker_session.upload_data(\n",
    "    \"data\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=f\"{prefix}/MNIST-data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8637d-5bc6-4af8-8cc7-76d1d472e4fa",
   "metadata": {},
   "source": [
    "We'll then pass this dictionary to the `fit()` function to tell SageMaker were to find the training and testing data. In this case, they two data channel will point at the same S3 prefix, but in general they file organization might be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf8b13-0492-4772-8442-9aec0cf6bddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_inputs = {\"train\": data_s3_uri, \"test\": data_s3_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130d82b-37f7-405c-87bf-4eef59d1f431",
   "metadata": {},
   "source": [
    "## Configure profiling rules\n",
    "During the training we'll use [SageMaker Debugger](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html) to monitor the training process, and log tensor and scalar outputs. We also include some automatic auditing of the training process, leveraging few of the most common built-in debugger rules.  \n",
    "With SageMaker debugger, we can configure the hook that capture the data from the Training Job definition. We will also indicate the S3 prefix where to store the tensorflow-compatible outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d24ef7-eb54-4e42-8044-4798531cd5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"100\",\n",
    "        \"eval.save_interval\": \"10\",\n",
    "    }\n",
    ")\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path=f\"s3://{bucket}/{prefix}/tensorboard\"\n",
    ")\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79fefe",
   "metadata": {},
   "source": [
    "## Training Job with single GPU\n",
    "\n",
    "The code we'll use for the training job is in the `code` folder.\n",
    "- `mnist_pl.py` is the entry point script, it will be executed by the training job.\n",
    "- `requirements.txt` we included the libraries not already present in the training image.\n",
    "- `models.py` and `data_modules.py` container the Lightning modules for the model and data. they can easily be replaced with more complex models of your choice. To make integration with the SageMaker training easier, the scripts are designed to allow setting of the hyperparameters from the CLI, following the [recommended best practices](https://pytorch-lightning.readthedocs.io/en/stable/common/hyperparameters.html). \n",
    "- `sm_utils_functions.py` is a collection of convenience functions for integrating the training script with SageMaker Training.\n",
    "- `sm_logger.py` provides a [Lightning Logger](https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html#make-a-custom-logger) to integrate the training process with [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) with minimal code changes.\n",
    "- `sm_debug_callback.py` provides a Lightning Callback to capture tensors and metrics using SageMaker Debugger.\n",
    "\n",
    "\n",
    "We define the experiment name and the name of the experimental run, then define a PyTorch Estimator, and then start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a27b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Run(\n",
    "    experiment_name=\"pytorch-demo-mnist\",\n",
    "    run_name=name_from_base(\"1x1-gpu-ff\"),\n",
    ") as run:\n",
    "    estimator = PyTorch(\n",
    "        entry_point=\"mnist_pl.py\",\n",
    "        base_job_name=\"lightning-mnist-1x1\",\n",
    "        role=role,\n",
    "        source_dir=\"code\",\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.g4dn.xlarge\",\n",
    "        py_version=\"py38\",\n",
    "        framework_version=\"1.12.1\",\n",
    "        output_path=f\"s3://{bucket}/{prefix}\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        hyperparameters={\"batch_size\": 256, \"epochs\": 20},\n",
    "        rules=rules,\n",
    "        debugger_hook_config=hook_config,\n",
    "        tensorboard_output_config=tensorboard_output_config,\n",
    "        input_mode=\"FastFile\",\n",
    "        # keep_alive_period_in_seconds=20 * 60,  # Warm pool, useful if re-running the same job\n",
    "    )\n",
    "\n",
    "    estimator.fit(inputs=fit_inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c006c56-ce00-488b-8061-9226c042fd81",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can follow the training job progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b98f1",
   "metadata": {},
   "source": [
    "## Training Job with multiple GPUs on the same instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071aafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Run(\n",
    "    experiment_name=\"pytorch-demo-mnist\",\n",
    "    run_name=name_from_base(\"1x4-gpu\"),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    estimator = PyTorch(\n",
    "        entry_point=\"mnist_pl.py\",\n",
    "        base_job_name=\"lightning-mnist-1x4\",\n",
    "        role=role,\n",
    "        source_dir=\"code\",\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.g4dn.12xlarge\",\n",
    "        py_version=\"py38\",\n",
    "        framework_version=\"1.12.1\",\n",
    "        output_path=f\"s3://{bucket}/{prefix}\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        hyperparameters={\"batch_size\": 128, \"epochs\": 20},\n",
    "        debugger_hook_config=hook_config,\n",
    "        tensorboard_output_config=tensorboard_output_config,\n",
    "        input_mode=\"FastFile\",\n",
    "        # keep_alive_period_in_seconds=20 * 60,  # Warm pool, useful if re-running the same job\n",
    "    )\n",
    "\n",
    "    estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed822fa9",
   "metadata": {},
   "source": [
    "## Review the tracked metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2bfc79",
   "metadata": {},
   "source": [
    "After each training job is complete, the training, validation, and testing should be recorded as `Run`  within SageMaker experiment `pytorch-demo-mnist`. The run should also include a confusion matrix in the _chart_ tab  \n",
    " ![screen shot of confusion matrix](images/conf_mat.png)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/pytorch-1.12-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ab638aa00986aa0e6a7cdada5cec29e56efe27f3c426a028b4e96530cb216ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
